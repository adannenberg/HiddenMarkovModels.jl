var documenterSearchIndex = {"docs":
[{"location":"debugging/#Debugging","page":"Debugging","title":"Debugging","text":"","category":"section"},{"location":"debugging/#Numerical-overflow","page":"Debugging","title":"Numerical overflow","text":"","category":"section"},{"location":"debugging/","page":"Debugging","title":"Debugging","text":"The most frequent error you will encounter is an OverflowError during forward-backward, telling you that \"some values are infinite / NaN\". This can happen for a variety of reasons, so here are a few leads worth investigating:","category":"page"},{"location":"debugging/","page":"Debugging","title":"Debugging","text":"Increase the duration of the sequence / the number of sequences (to get more data)\nReduce the number of states (to make every one of them useful)\nAdd a prior to your transition matrix / observation distributions (to avoid degenerate behavior like zero variance in a Gaussian)\nPick a better initialization (to start closer to the supposed ground truth)\nUse LogarithmicNumbers.jl in strategic places (to guarantee numerical stability). Note that these numbers don't play nicely with Distributions.jl, so you may have to roll out your own observation distribution.","category":"page"},{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"HiddenMarkovModels","category":"page"},{"location":"api/#HiddenMarkovModels","page":"API reference","title":"HiddenMarkovModels","text":"HiddenMarkovModels\n\nA Julia package for HMM modeling, simulation, inference and learning.\n\nExports\n\nAbstractHMM\nAbstractHiddenMarkovModel\nHMM\nHiddenMarkovModel\nbaum_welch\ncheck_hmm\nfit!\nforward\nforward_backward\ninitialization\nlogdensityof\nobs_distributions\nrand_prob_vec\nrand_trans_mat\ntransition_matrix\nviterbi\n\n\n\n\n\n","category":"module"},{"location":"api/#Types","page":"API reference","title":"Types","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"AbstractHiddenMarkovModel\nHiddenMarkovModel\nAbstractHMM\nHMM","category":"page"},{"location":"api/#HiddenMarkovModels.AbstractHiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.AbstractHiddenMarkovModel","text":"AbstractHiddenMarkovModel\n\nAbstract supertype for an HMM amenable to simulation, inference and learning.\n\nInterface\n\nTo create your own subtype of AbstractHiddenMarkovModel, you need to implement the following methods:\n\nlength(hmm)\neltype(hmm, obs)\ninitialization(hmm)\ntransition_matrix(hmm)\nobs_distributions(hmm)\nfit!(hmm, init_count, trans_count, obs_seq, state_marginals) (optional)\n\nApplicable functions\n\nAny HMM object which satisfies the interface can be given as input to the following functions:\n\nrand(rng, hmm, T)\nlogdensityof(hmm, obs_seq)\nforward(hmm, obs_seq)\nviterbi(hmm, obs_seq)\nforward_backward(hmm, obs_seq)\nbaum_welch(hmm, obs_seq) (if the optional fit! is implemented)\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModel","text":"struct HiddenMarkovModel{I<:(AbstractVector), T<:(AbstractMatrix), D<:(AbstractVector)} <: AbstractHiddenMarkovModel\n\nBasic implementation of an HMM.\n\nFields\n\ninit::AbstractVector: initial state probabilities\ntrans::AbstractMatrix: state transition matrix\ndists::AbstractVector: observation distributions\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.AbstractHMM","page":"API reference","title":"HiddenMarkovModels.AbstractHMM","text":"AbstractHMM\n\nAlias for the type AbstractHiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMM","page":"API reference","title":"HiddenMarkovModels.HMM","text":"HMM\n\nAlias for the type HiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#Basics","page":"API reference","title":"Basics","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"rand\nlength\neltype\ninitialization\ntransition_matrix\nobs_distributions","category":"page"},{"location":"api/#Base.rand","page":"API reference","title":"Base.rand","text":"rand(hmm, T)\nrand(rng, hmm, T)\n\nSimulate hmm for T time steps. \n\n\n\n\n\n","category":"function"},{"location":"api/#Base.length","page":"API reference","title":"Base.length","text":"length(hmm)\n\nReturn the number of states of hmm.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.eltype","page":"API reference","title":"Base.eltype","text":"eltype(hmm, obs)\n\nReturn a type that can accommodate forward-backward computations on observations similar to obs. It is typicall a promotion between the element type of the initialization, the element type of the transition matrix, and the type of an observation logdensity evaluated at obs.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.initialization","page":"API reference","title":"HiddenMarkovModels.initialization","text":"initialization(hmm)\n\nReturn the vector of initial state probabilities for hmm.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.transition_matrix","page":"API reference","title":"HiddenMarkovModels.transition_matrix","text":"transition_matrix(hmm)\n\nReturn the matrix of state transition probabilities for hmm.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.obs_distributions","page":"API reference","title":"HiddenMarkovModels.obs_distributions","text":"obs_distributions(hmm)\n\nReturn a vector of observation distributions for hmm.\n\nEach element dist of this vector must implement\n\nrand(rng, dist)\nDensityInterface.logdensityof(dist, obs)\n\n\n\n\n\n","category":"function"},{"location":"api/#Inference","page":"API reference","title":"Inference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"logdensityof\nforward\nviterbi\nforward_backward\nbaum_welch\nfit!","category":"page"},{"location":"api/#DensityInterface.logdensityof","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(hmm, obs_seq)\nlogdensityof(hmm, obs_seqs, nb_seqs)\n\nRun the forward algorithm to compute the posterior loglikelihood of observations for an HMM.\n\nWhether it is applied on one or multiple sequences, this function returns a number.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.forward","page":"API reference","title":"HiddenMarkovModels.forward","text":"forward(hmm, obs_seq)\nforward(hmm, obs_seqs, nb_seqs)\n\nRun the forward algorithm to infer the current state of an HMM.\n\nWhen applied on a single sequence, this function returns a tuple (α, logL) where\n\nα[i] is the posterior probability of state i at the end of the sequence\nlogL is the loglikelihood of the sequence\n\nWhen applied on multiple sequences, this function returns a vector of tuples.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.viterbi","page":"API reference","title":"HiddenMarkovModels.viterbi","text":"viterbi(hmm, obs_seq)\nviterbi(hmm, obs_seqs, nb_seqs)\n\nApply the Viterbi algorithm to infer the most likely state sequence of an HMM.\n\nWhen applied on a single sequence, this function returns a vector of integers. When applied on multiple sequences, it returns a vector of vectors of integers.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.forward_backward","page":"API reference","title":"HiddenMarkovModels.forward_backward","text":"forward_backward(hmm, obs_seq)\nforward_backward(hmm, obs_seqs, nb_seqs)\n\nRun the forward-backward algorithm to infer the posterior state and transition marginals of an HMM.\n\nWhen applied on a single sequence, this function returns a tuple (γ, ξ, logL) where\n\nγ is a matrix containing the posterior state marginals γ[i, t] \nlogL is the loglikelihood of the sequence\n\nWHen applied on multiple sequences, it returns a vector of tuples.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.baum_welch","page":"API reference","title":"HiddenMarkovModels.baum_welch","text":"baum_welch(hmm_init, obs_seq; kwargs...)\nbaum_welch(hmm_init, obs_seqs, nb_seqs; kwargs...)\n\nApply the Baum-Welch algorithm to estimate the parameters of an HMM starting from hmm_init.\n\nReturn a tuple (hmm_est, logL_evolution).\n\nKeyword arguments\n\natol: minimum loglikelihood increase at an iteration of the algorithm (otherwise the algorithm is deemed to have converged)\nmax_iterations: maximum number of iterations of the algorithm\nloglikelihood_increasing: whether to throw an error if the loglikelihood decreases\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.fit!","page":"API reference","title":"StatsAPI.fit!","text":"fit!(hmm, init_count, trans_count, obs_seq, state_marginals)\n\nUpdate hmm in-place based on information generated during forward-backward.\n\nThis method is only necessary for the Baum-Welch algorithm.\n\nArguments\n\ninit_count::Vector: posterior initialization counts for each state (size N)\ntrans_count::AbstractMatrix: posterior transition counts for each state (size (N, N))\nobs_seq::Vector: sequence of observation, possibly concatenated (size T)\nstate_marginals::Matrix: posterior probabilities of being in each state at each time, to be used as weights during maximum likelihood fitting of the observation distributions (size (N, T)).\n\nSee also\n\nBaumWelchStorage\nForwardBackwardStorage\n\n\n\n\n\n","category":"function"},{"location":"api/#Misc","page":"API reference","title":"Misc","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"check_hmm\nrand_prob_vec\nrand_trans_mat","category":"page"},{"location":"api/#HiddenMarkovModels.check_hmm","page":"API reference","title":"HiddenMarkovModels.check_hmm","text":"check_hmm(hmm::AbstractHMM)\n\nVerify that hmm satisfies basic assumptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.rand_prob_vec","page":"API reference","title":"HiddenMarkovModels.rand_prob_vec","text":"rand_prob_vec(N)\nrand_prob_vec(rng, N)\n\nGenerate a random probability distribution of size N.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.rand_trans_mat","page":"API reference","title":"HiddenMarkovModels.rand_trans_mat","text":"rand_trans_mat(N)\nrand_trans_mat(rng, N)\n\nGenerate a random transition matrix of size (N, N).\n\n\n\n\n\n","category":"function"},{"location":"api/#Internals","page":"API reference","title":"Internals","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"HiddenMarkovModels.ForwardStorage\nHiddenMarkovModels.ViterbiStorage\nHiddenMarkovModels.ForwardBackwardStorage\nHiddenMarkovModels.BaumWelchStorage\nHiddenMarkovModels.fit_element_from_sequence!\nHiddenMarkovModels.LightDiagNormal\nHiddenMarkovModels.PermutedHMM","category":"page"},{"location":"api/#HiddenMarkovModels.ForwardStorage","page":"API reference","title":"HiddenMarkovModels.ForwardStorage","text":"struct ForwardStorage{R}\n\nStore forward quantities with element type R.\n\nThis storage is relative to a single sequence.\n\nFields\n\nThe only fields useful outside of the algorithm are αₜ and logL.\n\nlogL::Base.RefValue: total loglikelihood\nlogb::Vector: observation loglikelihoods logbₜ[i] = ℙ(Y[t] | X[t]=i)\nα::Vector: scaled forward messsages for a given time step\nα_next::Vector: same as α but for the next time step\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.ViterbiStorage","page":"API reference","title":"HiddenMarkovModels.ViterbiStorage","text":"struct ViterbiStorage{R}\n\nStore Viterbi quantities with element type R.\n\nThis storage is relative to a single sequence.\n\nFields\n\nThe only field useful outside of the algorithm is q.\n\nlogb::Vector: observation loglikelihoods at a given time step\nδ::Vector: highest path scores when accounting for the first t observations and ending at a given state\nδ_prev::Vector: same as δ but for the previous time step\nδA::Vector: temporary variable used to store products δ_prev .* A[:, j]\nψ::Matrix{Int64}: penultimate state maximizing the path score\nq::Vector{Int64}: most likely state at each time q[t] = argmaxᵢ ℙ(X[t]=i | Y[1:T])\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.ForwardBackwardStorage","page":"API reference","title":"HiddenMarkovModels.ForwardBackwardStorage","text":"struct ForwardBackwardStorage{R, M<:AbstractArray{R, 2}}\n\nStore forward-backward quantities with element type R.\n\nThis storage is relative to a single sequence.\n\nFields\n\nThe only fields useful outside of the algorithm are γ, ξ and logL.\n\nlogL::Base.RefValue: total loglikelihood\nα::Matrix: scaled forward messsages α[i,t] proportional to ℙ(Y[1:t], X[t]=i) (up to a function of t)\nβ::Matrix: scaled backward messsages β[i,t] proportional to ℙ(Y[t+1:T] | X[t]=i) (up to a function of t)\nγ::Matrix: posterior state marginals γ[i,t] = ℙ(X[t]=i | Y[1:T])\nξ::Vector{M} where {R, M<:AbstractMatrix{R}}: posterior transition marginals ξ[t][i,j] = ℙ(X[t:t+1]=(i,j) | Y[1:T])\nc::Vector: forward message inverse normalizations c[t] = 1 / sum(α[:,t])\nlogB::Matrix: observation loglikelihoods logB[i,t] = ℙ(Y[t] | X[t]=i)\nlogm::Vector: maximum of the observation loglikelihoods logm[t] = maximum(logB[:, t])\nB̃::Matrix: numerically stabilized observation likelihoods B̃[i,t] = exp.(logB[i,t] - logm[t])\nB̃β::Matrix: product B̃β[i,t] = B̃[i,t] * β[i,t]\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.BaumWelchStorage","page":"API reference","title":"HiddenMarkovModels.BaumWelchStorage","text":"struct BaumWelchStorage{R, M<:AbstractArray{R, 2}}\n\nStore Baum-Welch quantities with element type R.\n\nThis storage is relative to a several sequences.\n\nFields\n\nThese fields (except limits) are passed to the fit!(hmm, ...) method along with obs_seqs_concat. \n\ninit_count::Vector: posterior initialization counts for each state\ntrans_count::AbstractMatrix: posterior transition counts for each state\nstate_marginals_concat::Matrix: concatenation along time of the state marginal matrices γ[i,t] = ℙ(X[t]=i | Y[1:T]) for all observation sequences\nlimits::Vector{Int64}: temporal separations between observation sequences: state_marginals_concat[limits[k]+1:limits[k+1]] refers to sequence k\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.fit_element_from_sequence!","page":"API reference","title":"HiddenMarkovModels.fit_element_from_sequence!","text":"fit_element_from_sequence!(dists, i, x, w)\n\nModify the i-th element of dists by fitting it to an observation sequence x with associated weight sequence w.\n\nThe default behavior is a fallback on StatsAPI.fit!, which users are encouraged to implement if their observation distributions are mutable. If this is not possible, please override fit_element_from_sequence! directly.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.LightDiagNormal","page":"API reference","title":"HiddenMarkovModels.LightDiagNormal","text":"struct LightDiagNormal{T1, T2, T3, V1<:AbstractArray{T1, 1}, V2<:AbstractArray{T2, 1}, V3<:AbstractArray{T3, 1}}\n\nAn HMMs-compatible implementation of a multivariate normal distribution with diagonal covariance, enabling allocation-free estimation.\n\nThis is not part of the public API and is expected to change.\n\nFields\n\nμ::AbstractVector: vector of means\nσ::AbstractVector: vector of standard deviations\nlogσ::AbstractVector: vector of log standard deviations\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.PermutedHMM","page":"API reference","title":"HiddenMarkovModels.PermutedHMM","text":"struct PermutedHMM{H<:AbstractHiddenMarkovModel} <: AbstractHiddenMarkovModel\n\nWrapper around an AbstractHMM that permutes its states.\n\nThis is computationally inefficient and mostly useful for evaluation.\n\nFields\n\nhmm::AbstractHiddenMarkovModel: the old HMM\nperm::Vector{Int64}: a permutation such that state i in the new HMM corresponds to state perm[i] in the old\n\n\n\n\n\n","category":"type"},{"location":"api/#Notations","page":"API reference","title":"Notations","text":"","category":"section"},{"location":"api/#Integers","page":"API reference","title":"Integers","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"N: number of states\nD: dimension of the observations\nT: trajectory length\nK: number of trajectories","category":"page"},{"location":"api/#Models-and-simulations","page":"API reference","title":"Models and simulations","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"p or init: initialization (vector of state probabilities)\nA or trans: transition_matrix (matrix of transition probabilities)\nd or dists: observation distribution (vector of rand-able and logdensityof-able objects)\nstate_seq: a sequence of states (vector of integers)\nobs_seq: a sequence of observations (vector of individual observations)\nobs_seqs: several sequences of observations\nnb_seqs: number of observation sequences","category":"page"},{"location":"api/#Forward-backward","page":"API reference","title":"Forward backward","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"(log)b: vector of observation (log)likelihoods by state for an individual observation\n(log)B: matrix of observation (log)likelihoods by state for a sequence of observations\nα: scaled forward variables\nβ: scaled backward variables\nγ: state marginals\nξ: transition marginals\nlogL: posterior loglikelihood of a sequence of observations","category":"page"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"","category":"page"},{"location":"builtin/#Tutorial-built-in-HMM","page":"Built-in HMM","title":"Tutorial - built-in HMM","text":"","category":"section"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"using Distributions\nusing HiddenMarkovModels\n\nusing Random; Random.seed!(63)","category":"page"},{"location":"builtin/#Construction","page":"Built-in HMM","title":"Construction","text":"","category":"section"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Creating a model:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"function gaussian_hmm(N; noise=0)\n    p = ones(N) / N  # initial distribution\n    A = rand_trans_mat(N)  # transition matrix\n    d = [Normal(i + noise * randn(), 0.5) for i in 1:N]  # observation distributions\n    return HMM(p, A, d)\nend","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Checking its contents:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"N = 3\nhmm = gaussian_hmm(N)\ntransition_matrix(hmm)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"obs_distributions(hmm)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Simulating a sequence:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"T = 1000\nstate_seq, obs_seq = rand(hmm, T);\nfirst(state_seq, 10)'","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"first(obs_seq, 10)'","category":"page"},{"location":"builtin/#Inference","page":"Built-in HMM","title":"Inference","text":"","category":"section"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Computing the loglikelihood of an observation sequence:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"logdensityof(hmm, obs_seq)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Inferring the most likely state sequence:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"most_likely_state_seq = viterbi(hmm, obs_seq);\nfirst(most_likely_state_seq, 10)'","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Learning the parameters based on an observation sequence:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"hmm_init = gaussian_hmm(N, noise=1)\nhmm_est, logL_evolution = baum_welch(hmm_init, obs_seq);\nfirst(logL_evolution), last(logL_evolution)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Correcting state order because we know observation means are increasing in the true model:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"d_est = obs_distributions(hmm_est)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"perm = sortperm(1:3, by=i->d_est[i].μ)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"hmm_est = HiddenMarkovModels.PermutedHMM(hmm_est, perm)","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Evaluating errors:","category":"page"},{"location":"builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"cat(transition_matrix(hmm_est), transition_matrix(hmm), dims=3)","category":"page"},{"location":"features/#Alternatives-features","page":"Features","title":"Alternatives - features","text":"","category":"section"},{"location":"features/","page":"Features","title":"Features","text":"We compare features among the following Julia packages:","category":"page"},{"location":"features/","page":"Features","title":"Features","text":"HiddenMarkovModels.jl (abbreviated to HMMs.jl)\nHMMBase.jl\nHMMGradients.jl","category":"page"},{"location":"features/","page":"Features","title":"Features","text":"We discard MarkovModels.jl because its focus is GPU computation. There are also more generic packages for probabilistic programming, which are able to perform MCMC or variational inference (eg. Turing.jl) but we leave those aside.","category":"page"},{"location":"features/","page":"Features","title":"Features","text":" HMMs.jl HMMBase.jl HMMGradients.jl\nAlgorithms Sim, FB, Vit, BW Sim, FB, Vit, BW FB\nObservation types anything Number / Vector anything\nObservation distributions DensityInterface.jl Distributions.jl manual\nNumber types anything Float64 AbstractFloat\nPriors / structures possible no possible\nAutomatic differentiation yes no yes\nMultiple sequences yes no yes\nLinear algebra yes yes no\nLogarithmic probabilities halfway halfway yes","category":"page"},{"location":"features/","page":"Features","title":"Features","text":"Sim = Simulation, FB = Forward-Backward, Vit = Viterbi, BW = Baum-Welch","category":"page"},{"location":"roadmap/#Roadmap","page":"Roadmap","title":"Roadmap","text":"","category":"section"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"Here are some of the things that I would like to work on soon-ish:","category":"page"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"numerical stability in large-dimensional settings with sparse transitions\nSIMD optimization with LoopVectorization.jl or Tullio.jl\nspectral estimation methods\ninput-output HMMs in my other package ControlledMarkovModels.jl","category":"page"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"Contributors are welcome!","category":"page"},{"location":"custom/#Tutorial-custom-HMM","page":"Custom HMM","title":"Tutorial - custom HMM","text":"","category":"section"},{"location":"custom/","page":"Custom HMM","title":"Custom HMM","text":"using Distributions\nusing HiddenMarkovModels\n\nusing Random; Random.seed!(63)","category":"page"},{"location":"custom/","page":"Custom HMM","title":"Custom HMM","text":"Here we demonstrate how to build your own HMM structure satisfying the interface.","category":"page"},{"location":"custom/","page":"Custom HMM","title":"Custom HMM","text":"danger: Danger\nWork in progress.","category":"page"},{"location":"background/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"background/#What-are-HMMs?","page":"Background","title":"What are HMMs?","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Hidden Markov Models (HMMs for short) are a statistical modeling framework that is ubiquitous in signal processing, bioinformatics and plenty of other fields. They capture the distribution of an observation sequence (Y_t) by assuming the existence of a latent state sequence (X_t) such that:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"the sequence (X_t) follows a (discrete time, discrete space) Markov chain\nfor each t, the distribution of Y_t is entirely determined by the value of X_t","category":"page"},{"location":"background/#What-can-we-do-with-them?","page":"Background","title":"What can we do with them?","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Imagine we are given an observation sequence (Y_t) and a parametric family of HMMs mathbbP_theta  theta in Theta. We can list several fundamental problems, each of which has a solution that relies on dynamic programming:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Problem Goal Algorithm\nEvaluation Likelihood of the observation sequence mathbbP_theta(Y_1T) Forward\nInference State marginals mathbbP_theta(X_t vert Y_1T) Forward-backward\nDecoding Most likely state sequence undersetX_1TmathrmargmaxmathbbP_theta(X_1T vert Y_1T) Viterbi\nLearning Best parameter undersetthetamathrmargmaxmathbbP_theta(Y_1T) Baum-Welch","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Our whole package is based on the tutorial by (Rabiner, 1989), you can refer to it for more details.","category":"page"},{"location":"background/#Bibliography","page":"Background","title":"Bibliography","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Qin, F.; Auerbach, A. and Sachs, F. (2000). A Direct Optimization Approach to Hidden Markov Modeling for Single Channel Kinetics. Biophysical Journal 79, 1915–1927. Accessed on Sep 10, 2023.\n\n\n\nRabiner, L. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE 77, 257–286. Accessed on Sep 10, 2023.\n\n\n\n","category":"page"},{"location":"formulas/#Formulas","page":"Formulas","title":"Formulas","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Suppose we are given observations Y_1  Y_T, with hidden states X_1  X_T. Following (Rabiner, 1989), we use the following notations:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"let pi in mathbbR^N be the initial state distribution pi_i = mathbbP(X_1 = i)\nlet A in mathbbR^N times N be the transition matrix a_ij = mathbbP(X_t+1=j  X_t = i)\nlet B in mathbbR^N times T be the matrix of statewise observation likelihoods b_it = mathbbP(Y_t  X_t = i)","category":"page"},{"location":"formulas/#Vanilla-forward-backward","page":"Formulas","title":"Vanilla forward-backward","text":"","category":"section"},{"location":"formulas/#Recursion","page":"Formulas","title":"Recursion","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The forward and backward variables are defined by","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_it  = mathbbP(Y_1t X_t=i) \nbeta_it  = mathbbP(Y_t+1T  X_t=i)\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"They are initialized with","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_i1  = pi_i b_i1 \nbeta_iT  = 1\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"and satisfy the dynamic programming equations","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_jt+1  = left(sum_i=1^N alpha_it a_ijright) b_jt+1 \nbeta_it  = sum_j=1^N a_ij b_jt+1 beta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Likelihood","page":"Formulas","title":"Likelihood","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The likelihood of the whole sequence of observations is given by","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"mathcalL = mathbbP(Y_1T) = sum_i=1^N alpha_iT","category":"page"},{"location":"formulas/#Marginals","page":"Formulas","title":"Marginals","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"We notice that","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_it beta_it  = mathbbP(Y_1T X_t=i) \nalpha_it a_ij b_jt+1 beta_jt+1  = mathbbP(Y_1T X_t=i X_t+1=j)\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Thus we deduce the one-state and two-state marginals","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\ngamma_it  = mathbbP(X_t=i  Y_1T) = frac1mathcalL alpha_it beta_it \nxi_ijt  = mathbbP(X_t=i X_t+1=j  Y_1T) = frac1mathcalL alpha_it a_ij b_jt+1 beta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Derivatives","page":"Formulas","title":"Derivatives","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"According to (Qin et al., 2000), derivatives of the likelihood can be obtained as follows:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial pi_i = beta_i1 b_i1 \nfracpartial mathcalLpartial a_ij = sum_t=1^T-1 alpha_it b_jt+1 beta_jt+1 \nfracpartial mathcalLpartial b_j1 = pi_j beta_j1 \nfracpartial mathcalLpartial b_jt = left(sum_i=1^N alpha_it-1 a_ijright) beta_jt \nendalign*","category":"page"},{"location":"formulas/#Scaled-forward-backward","page":"Formulas","title":"Scaled forward-backward","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"In this package, we use a slightly different version of the algorithm, including both the traditional scaling of (Rabiner, 1989) and a normalization of B using m_t = max_i b_it.","category":"page"},{"location":"formulas/#Recursion-2","page":"Formulas","title":"Recursion","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The variables are initialized with","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nhatalpha_i1  = pi_i fracb_i1m_1  c_1  = frac1sum_i hatalpha_i1  baralpha_i1  = c_1 hatalpha_i1 \nhatbeta_iT  = 1   barbeta_1T = c_T hatbeta_1T\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"and satisfy the dynamic programming equations","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nhatalpha_jt+1  = left(sum_i=1^N baralpha_it a_ijright) fracb_jt+1m_t+1  c_t+1  = frac1sum_j hatalpha_jt+1  baralpha_jt+1 = c_t+1 hatalpha_jt+1 \nhatbeta_it  = sum_j=1^N a_ij fracb_jt+1m_t+1 barbeta_jt+1   barbeta_jt = c_t hatbeta_jt\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"In terms of the original variables, we find","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nbaralpha_it = alpha_it left(prod_s=1^t fracc_sm_sright) \nbarbeta_it = beta_it left(c_t prod_s=t+1^T fracc_sm_sright)\nendalign*","category":"page"},{"location":"formulas/#Likelihood-2","page":"Formulas","title":"Likelihood","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Since we normalized baralpha at each time step,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"1 = sum_i=1^N baralpha_iT = left(sum_i=1^N alpha_iTright) left(prod_s=1^T fracc_sm_sright) ","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"which means","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"mathcalL = sum_i=1^N alpha_iT = prod_s=1^T fracm_sc_s","category":"page"},{"location":"formulas/#Marginals-2","page":"Formulas","title":"Marginals","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"We can now express the marginals using scaled variables:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\ngamma_it  = frac1mathcalL alpha_it beta_it = frac1mathcalL left(baralpha_it prod_s=1^t fracm_sc_sright) left(barbeta_it frac1c_t prod_s=t+1^T fracm_sc_sright) \n= frac1mathcalL fracbaralpha_it barbeta_itc_t left(prod_s=1^T fracm_sc_sright) = fracbaralpha_it barbeta_itc_t\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nxi_ijt  = frac1mathcalL alpha_it a_ij b_jt+1 beta_jt+1 \n= frac1mathcalL  left(baralpha_it prod_s=1^t fracm_sc_sright) a_ij b_jt+1 left(barbeta_jt+1 frac1c_t+1 prod_s=t+2^T fracm_sc_sright) \n= frac1mathcalL  baralpha_it a_ij fracb_jt+1m_t+1 barbeta_jt+1 left(prod_s=1^T fracm_sc_sright) \n= baralpha_it a_ij fracb_jt+1m_t+1 barbeta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Derivatives-2","page":"Formulas","title":"Derivatives","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"And we also need to adapt the derivatives. For the initial distribution,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial pi_i = beta_i1 b_i1 = left(barbeta_i1 frac1c_1 prod_s=2^T fracm_sc_s right) b_i1 \n= left(prod_s=1^T fracm_sc_sright) barbeta_i1 fracb_i1m_1  = mathcalL barbeta_i1 fracb_i1m_1 \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"For the transition matrix,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial a_ij = sum_t=1^T-1 alpha_it b_jt+1 beta_jt+1 \n= sum_t=1^T-1 left(baralpha_it prod_s=1^t fracm_sc_s right) b_jt+1 left(barbeta_jt+1 frac1c_t+1 prod_s=t+2^T fracm_sc_s right) \n= sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 left(prod_s=1^T fracm_sc_s right) \n= mathcalL sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"And for the statewise observation likelihoods,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial b_j1 = pi_j beta_j1 = pi_j barbeta_j1 frac1c_1 prod_s=2^T fracm_sc_s = mathcalL pi_j barbeta_j1 frac1m_1\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial b_jt = left(sum_i=1^N alpha_it-1 a_ijright) beta_jt \n= sum_i=1^N left(baralpha_it-1 prod_s=1^t-1 fracm_sc_sright) a_ij left(barbeta_jt frac1c_t prod_s=t+1^T fracm_sc_s right) \n= sum_i=1^N baralpha_it-1 a_ij barbeta_jt frac1m_t left(prod_s=1^T fracm_sc_sright) \n= mathcalL sum_i=1^N baralpha_it-1 a_ij barbeta_jt frac1m_t \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Finally, we note that","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"fracpartial log mathcalLpartial log b_jt = fracpartial log mathcalLpartial b_jt b_jt","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"To sum up,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial log mathcalLpartial pi_i = fracb_i1m_1 barbeta_i1 \nfracpartial log mathcalLpartial a_ij = sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 \nfracpartial log mathcalLpartial log b_j1 = pi_j fracb_j1m_1 barbeta_j1 = fracbaralpha_j1 barbeta_j1c_1 = gamma_j1 \nfracpartial log mathcalLpartial log b_jt = sum_i=1^N baralpha_it-1 a_ij fracb_jtm_t barbeta_jt = fracbaralpha_jt barbeta_jtc_t = gamma_jt\nendalign*","category":"page"},{"location":"","page":"Home","title":"Home","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/README.md\"","category":"page"},{"location":"#HiddenMarkovModels.jl","page":"Home","title":"HiddenMarkovModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: DOI) (Image: Aqua QA) (Image: JET)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Julia package for HMM modeling, simulation, inference and learning.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package can be installed using Julia's package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add HiddenMarkovModels","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, you can create your first HMM as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Distributions, HiddenMarkovModels\ninit = [0.2, 0.8]\ntrans = [0.1 0.9; 0.7 0.3]\ndists = [Normal(-1), Normal(1)]\nhmm = HMM(init, trans, dists)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Take a look at the documentation to know what to do next!","category":"page"},{"location":"#Main-features","page":"Home","title":"Main features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is generic. Observations can be arbitrary Julia objects, not just scalars or arrays. Their distributions only need to implement rand(rng, dist) and logdensityof(dist, x) from DensityInterface.jl. Number types are not restricted to floating point, and automatic differentiation is supported in forward mode (ForwardDiff.jl) and reverse mode (ChainRules.jl).","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is fast. All the inference functions have allocation-free versions, which leverage efficient linear algebra subroutines. Multithreading is used to parallelize computations across sequences, and compatibility with various array types is ensured. We include extensive benchmarks against Julia and Python competitors thanks to BenchmarkTools.jl and PythonCall.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is reliable. It gives the same results as the previous reference package HMMBase.jl up to numerical accuracy. The test suite incorporates quality checks with Aqua.jl, as well as linting and type stability checks with JET.jl. A detailed documentation will help you find the functions you need.","category":"page"},{"location":"","page":"Home","title":"Home","text":"But this package is limited in scope. It is designed for HMMs with a small number of states, because memory and runtime scale quadratically (even if the transitions are sparse). It is also meant to perform best on a CPU, and not tested at all on GPUs.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you spot a bug or want to ask about a new feature, please open an issue on the GitHub repository. Once the issue receives positive feedback, feel free to try and fix it with a pull request that follows the BlueStyle guidelines.","category":"page"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A big thank you to Maxime Mouchet and Jacob Schreiber, the respective lead devs of HMMBase.jl and pomegranate, for their help and advice. Logo by Clément Mantoux based on a portrait of Andrey Markov.","category":"page"}]
}
