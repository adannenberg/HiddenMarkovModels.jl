var documenterSearchIndex = {"docs":
[{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"HiddenMarkovModels\nHMMs","category":"page"},{"location":"api/#HiddenMarkovModels","page":"API reference","title":"HiddenMarkovModels","text":"HiddenMarkovModels\n\nA Julia package for HMM modeling, simulation, inference and learning.\n\n\n\n\n\n","category":"module"},{"location":"api/#HiddenMarkovModels.HMMs","page":"API reference","title":"HiddenMarkovModels.HMMs","text":"HMMs\n\nAlias for the module HiddenMarkovModels.\n\n\n\n\n\n","category":"module"},{"location":"api/#Types","page":"API reference","title":"Types","text":"","category":"section"},{"location":"api/#Markov-chains","page":"API reference","title":"Markov chains","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"AbstractMarkovChain\nMarkovChain\nAbstractMC\nMC","category":"page"},{"location":"api/#HiddenMarkovModels.AbstractMarkovChain","page":"API reference","title":"HiddenMarkovModels.AbstractMarkovChain","text":"AbstractMarkovChain\n\nAbstract supertype for a Markov chain amenable to simulation, inference and learning.\n\nRequired interface\n\ninitial_distribution(mc)\ntransition_matrix(mc)\nfit!(mc, init_count, trans_count) (optional)\n\nApplicable methods\n\nrand([rng,] mc, T)\nlogdensityof(mc, state_seq)\nfit(mc, state_seq_or_seqs) (if fit! is implemented)\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.MarkovChain","page":"API reference","title":"HiddenMarkovModels.MarkovChain","text":"MarkovChain <: AbstractMarkovChain\n\nBasic implementation of a discrete-state Markov chain.\n\nFields\n\ninit::AbstractVector: initial state probabilities\ntrans::AbstractMatrix: state transition matrix\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.AbstractMC","page":"API reference","title":"HiddenMarkovModels.AbstractMC","text":"AbstractMC\n\nAlias for the type AbstractMarkovChain.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.MC","page":"API reference","title":"HiddenMarkovModels.MC","text":"MC\n\nAlias for the type MarkovChain.\n\n\n\n\n\n","category":"type"},{"location":"api/#Hidden-Markov-Models","page":"API reference","title":"Hidden Markov Models","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"AbstractHiddenMarkovModel\nHiddenMarkovModel\nAbstractHMM\nHMM","category":"page"},{"location":"api/#HiddenMarkovModels.AbstractHiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.AbstractHiddenMarkovModel","text":"AbstractHiddenMarkovModel <: AbstractMarkovChain\n\nAbstract supertype for an HMM amenable to simulation, inference and learning.\n\nRequired interface\n\ninitial_distribution(hmm)\ntransition_matrix(hmm)\nobs_distribution(hmm, i)\nfit!(hmm, init_count, trans_count, obs_seq, state_marginals) (optional)\n\nApplicable methods\n\nrand([rng,] hmm, T)\nlogdensityof(hmm, obs_seq) / logdensityof(hmm, obs_seqs, nb_seqs)\nforward(hmm, obs_seq) / forward(hmm, obs_seqs, nb_seqs)\nviterbi(hmm, obs_seq) / viterbi(hmm, obs_seqs, nb_seqs)\nforward_backward(hmm, obs_seq) / forward_backward(hmm, obs_seqs, nb_seqs)\nbaum_welch(hmm, obs_seq) / baum_welch(hmm, obs_seqs, nb_seqs) if fit! is implemented\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModel","text":"HiddenMarkovModel{D} <: AbstractHiddenMarkovModel\n\nBasic implementation of an HMM.\n\nFields\n\ninit::AbstractVector: initial state probabilities\ntrans::AbstractMatrix: state transition matrix\ndists::AbstractVector{D}: observation distributions\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.AbstractHMM","page":"API reference","title":"HiddenMarkovModels.AbstractHMM","text":"AbstractHMM\n\nAlias for the type AbstractHiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMM","page":"API reference","title":"HiddenMarkovModels.HMM","text":"HMM\n\nAlias for the type HiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#Basics","page":"API reference","title":"Basics","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"rand\nlength\ninitial_distribution\ntransition_matrix\nobs_distribution","category":"page"},{"location":"api/#Base.rand","page":"API reference","title":"Base.rand","text":"rand([rng=default_rng(),] mc::AbstractMarkovChain, T)\n\nSimulate mc for T time steps with a specified rng.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.length","page":"API reference","title":"Base.length","text":"length(mc::AbstractMarkovChain)\n\nReturn the number of states of model.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.initial_distribution","page":"API reference","title":"HiddenMarkovModels.initial_distribution","text":"initial_distribution(mc::AbstractMarkovChain)\n\nReturn the initial state probabilities of mc.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.transition_matrix","page":"API reference","title":"HiddenMarkovModels.transition_matrix","text":"transition_matrix(mc::AbstractMarkovChain)\n\nReturn the state transition probabilities of mc.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.obs_distribution","page":"API reference","title":"HiddenMarkovModels.obs_distribution","text":"obs_distribution(hmm::AbstractHMM, i)\n\nReturn the observation distribution of hmm associated with state i.\n\nThe returned object dist must implement\n\nrand(rng, dist)\nDensityInterface.logdensityof(dist, x)\n\n\n\n\n\n","category":"function"},{"location":"api/#Inference","page":"API reference","title":"Inference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"logdensityof\nforward\nviterbi\nforward_backward","category":"page"},{"location":"api/#DensityInterface.logdensityof","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(mc, state_seq)\n\nCompute the loglikelihood of a single state sequence for a Markov chain.\n\n\n\n\n\nlogdensityof(hmm, obs_seq)\n\nApply the forward algorithm to compute the loglikelihood of a single observation sequence for an HMM.\n\nReturn a number.\n\n\n\n\n\nlogdensityof(hmm, obs_seqs, nb_seqs)\n\nApply the forward algorithm to compute the total loglikelihood of multiple observation sequences for an HMM.\n\nReturn a number.\n\nwarning: Multithreading\nThis function is parallelized across sequences.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.forward","page":"API reference","title":"HiddenMarkovModels.forward","text":"forward(hmm, obs_seq)\n\nApply the forward algorithm to an HMM.\n\nReturn a tuple (α, logL) where\n\nlogL is the loglikelihood of the sequence\nα[i] is the posterior probability of state i at the end of the sequence.\n\n\n\n\n\nforward(hmm, obs_seqs, nb_seqs)\n\nApply the forward algorithm to an HMM, based on multiple observation sequences.\n\nReturn a vector of tuples (αₖ, logLₖ), where\n\nlogLₖ is the loglikelihood of sequence k\nαₖ[i] is the posterior probability of state i at the end of sequence k\n\nwarning: Multithreading\nThis function is parallelized across sequences.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.viterbi","page":"API reference","title":"HiddenMarkovModels.viterbi","text":"viterbi(hmm, obs_seq)\n\nApply the Viterbi algorithm to compute the most likely state sequence of an HMM.\n\nReturn a vector of integers.\n\n\n\n\n\nviterbi(hmm, obs_seqs, nb_seqs)\n\nApply the Viterbi algorithm to compute the most likely state sequences of an HMM, based on multiple observation sequences.\n\nReturn a vector of vectors of integers.\n\nwarning: Multithreading\nThis function is parallelized across sequences.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.forward_backward","page":"API reference","title":"HiddenMarkovModels.forward_backward","text":"forward_backward(hmm, obs_seq)\n\nApply the forward-backward algorithm to estimate the posterior state marginals of an HMM.\n\nReturn a ForwardBackwardStorage.\n\n\n\n\n\nforward_backward(hmm, obs_seqs, nb_seqs)\n\nApply the forward-backward algorithm to estimate the posterior state marginals of an HMM, based on multiple observation sequences.\n\nReturn a vector of ForwardBackwardStorage objects.\n\nwarning: Multithreading\nThis function is parallelized across sequences.\n\n\n\n\n\n","category":"function"},{"location":"api/#Learning","page":"API reference","title":"Learning","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"fit!\nfit\nbaum_welch","category":"page"},{"location":"api/#StatsAPI.fit!","page":"API reference","title":"StatsAPI.fit!","text":"fit!(mc::MC, init_count, trans_count)\n\nUpdate mc in-place based on information generated from a state sequence.\n\n\n\n\n\nfit!(hmm::HMM, init_count, trans_count, obs_seq, state_marginals)\n\nUpdate hmm in-place based on information generated during forward-backward.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.fit","page":"API reference","title":"StatsAPI.fit","text":"fit(mc, state_seq_or_seqs)\n\nFit a Markov chain of the same type as mc to one or several state sequence(s).\n\nBeware that mc must be an actual object of type MarkovChain, and not the type itself as is usually done eg. in Distributions.jl.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.baum_welch","page":"API reference","title":"HiddenMarkovModels.baum_welch","text":"baum_welch(\n    hmm_init, obs_seq;\n    atol, max_iterations, check_loglikelihood_increasing\n)\n\nApply the Baum-Welch algorithm to estimate the parameters of an HMM starting from hmm_init.\n\nReturn a tuple (hmm_est, logL_evolution).\n\nKeyword arguments\n\natol: Minimum loglikelihood increase at an iteration of the algorithm (otherwise the algorithm is deemed to have converged)\nmax_iterations: Maximum number of iterations of the algorithm\ncheck_loglikelihood_increasing: Whether to throw an error if the loglikelihood decreases\n\n\n\n\n\nbaum_welch(\n    hmm_init, obs_seqs, nb_seqs;\n    atol, max_iterations, check_loglikelihood_increasing\n)\n\nApply the Baum-Welch algorithm to estimate the parameters of an HMM starting from hmm_init, based on nb_seqs observation sequences.\n\nReturn a tuple (hmm_est, logL_evolution).\n\nwarning: Multithreading\nThis function is parallelized across sequences.\n\nKeyword arguments\n\natol: Minimum loglikelihood increase at an iteration of the algorithm (otherwise the algorithm is deemed to have converged)\nmax_iterations: Maximum number of iterations of the algorithm\ncheck_loglikelihood_increasing: Whether to throw an error if the loglikelihood decreases\n\n\n\n\n\n","category":"function"},{"location":"api/#Internals","page":"API reference","title":"Internals","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"HMMs.ForwardBackwardStorage\nHMMs.fit_element_from_sequence!\nHMMs.LightDiagNormal","category":"page"},{"location":"api/#HiddenMarkovModels.ForwardBackwardStorage","page":"API reference","title":"HiddenMarkovModels.ForwardBackwardStorage","text":"ForwardBackwardStorage{R}\n\nStore forward-backward quantities with element type R.\n\nFields\n\nLet X denote the vector of hidden states and Y denote the vector of observations. The following fields are part of the API:\n\nγ::Matrix{R}: posterior one-state marginals γ[i,t] = ℙ(X[t]=i | Y[1:T])\nξ::Array{R,3}: posterior two-state marginals ξ[i,j,t] = ℙ(X[t:t+1]=(i,j) | Y[1:T])\n\nThe following fields are internals and subject to change:\n\nα::Matrix{R}: scaled forward variables α[i,t] proportional to ℙ(Y[1:t], X[t]=i) (up to a function of t)\nβ::Matrix{R}: scaled backward variables β[i,t] proportional to ℙ(Y[t+1:T] | X[t]=i) (up to a function of t)\nc::Vector{R}: forward variable inverse normalizations c[t] = 1 / sum(α[:, t])\nlogm::Vector{R}: maximum of the observation loglikelihoods logB\nBscaled::Matrix{R}: numerically stabilized observation likelihoods B\nBβscaled::Matrix{R}: numerically stabilized product Bβ\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.fit_element_from_sequence!","page":"API reference","title":"HiddenMarkovModels.fit_element_from_sequence!","text":"fit_element_from_sequence!(dists, i, x, w)\n\nModify the i-th element of dists by fitting it to an observation sequence x with associated weight sequence w.\n\nThe default behavior is a fallback on StatsAPI.fit!, which users are encouraged to implement if their observation distributions are mutable. If this is not possible, please override fit_element_from_sequence! directly.\n\n\n\n\n\n","category":"function"},{"location":"api/#HiddenMarkovModels.LightDiagNormal","page":"API reference","title":"HiddenMarkovModels.LightDiagNormal","text":"LightDiagNormal\n\nAn HMMs-compatible implementation of a multivariate normal distribution with diagonal covariance, enabling allocation-free estimation.\n\nThis is not part of the public API and is expected to change.\n\n\n\n\n\n","category":"type"},{"location":"api/#Notations","page":"API reference","title":"Notations","text":"","category":"section"},{"location":"api/#Integers","page":"API reference","title":"Integers","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"N: number of states\nD: dimension of the observations\nT: trajectory length\nK: number of trajectories","category":"page"},{"location":"api/#Models-and-simulations","page":"API reference","title":"Models and simulations","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"p or init: initial_distribution (vector of state probabilities)\nA or trans: transition_matrix (matrix of transition probabilities)\ndists: observation distribution (vector of rand-able and logdensityof-able objects)\nstate_seq: a sequence of states (vector of integers)\nobs_seq: a sequence of observations (vector of individual observations)\nobs_seqs: several sequences of observations","category":"page"},{"location":"api/#Forward-backward","page":"API reference","title":"Forward backward","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"(log)b: vector of observation (log)likelihoods by state for an individual observation\n(log)B: matrix of observation (log)likelihoods by state for a sequence of observations\nα: scaled forward variables\nβ: scaled backward variables\nγ: one-state marginals\nξ: two-state marginals\nlogL: loglikelihood of a sequence of observations","category":"page"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"","category":"page"},{"location":"alt_performance/#Alternatives-performance","page":"Performance","title":"Alternatives - performance","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"We compare performance among the following packages:","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"HiddenMarkovModels.jl (abbreviated to HMMs.jl)\nHMMBase.jl\nhmmlearn\npomegranate","category":"page"},{"location":"alt_performance/#Numerical-results","page":"Performance","title":"Numerical results","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"The test case is an HMM with diagonal multivariate normal observations.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"danger: Why is this empty?\nThe benchmark suite is computationally expensive, and we only run it once for each new release. If the following section contains no plots and the links are broken, you're probably reading the development documentation or a local build of the website. Check out the stable documentation instead.","category":"page"},{"location":"alt_performance/#Single-sequence","page":"Performance","title":"Single sequence","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Full benchmark logs: results_single_sequence.csv.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Logdensity single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Viterbi single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Forward-backward single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Baum-Welch single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Here, pomegranate is not included because it is much slower on very small inputs.","category":"page"},{"location":"alt_performance/#Multiple-sequences","page":"Performance","title":"Multiple sequences","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Full benchmark logs: results_multiple_sequences.csv.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Logdensity single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"(Image: Plot - Baum-Welch single sequence benchmark)","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Here, HMMBase.jl is not included because it does not support multiple sequences.","category":"page"},{"location":"alt_performance/#Reproducibility","page":"Performance","title":"Reproducibility","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"These benchmarks were generated in the following environment: setup.txt.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"If you want to run them on your machine:","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Clone the HiddenMarkovModels.jl repository\nOpen a Julia REPL at the root\nRun the following commands\ninclude(\"benchmark/run_benchmarks.jl\")\ninclude(\"benchmark/process_benchmarks.jl\")","category":"page"},{"location":"alt_performance/#Remarks","page":"Performance","title":"Remarks","text":"","category":"section"},{"location":"alt_performance/#Allocations","page":"Performance","title":"Allocations","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"A major bottleneck of performance in Julia is memory allocations. The benchmarks for HMMs.jl thus employ a custom implementation of diagonal multivariate normals, which is entirely allocation-free.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"This partly explains the performance gap with HMMBase.jl as the dimension D grows beyond 1. Such a trick is also possible with HMMBase.jl, but slightly more demanding since it requires subtyping Distribution from Distributions.jl, instead of just implementing DensityInterface.jl. We might do it in future benchmarks.","category":"page"},{"location":"alt_performance/#Parallelism","page":"Performance","title":"Parallelism","text":"","category":"section"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"The packages we include have different approaches to parallelism, which can bias the evaluation in complex ways:","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"Package States N Observations D Sequences K\nHMMs.jl LinearAlgebra[2] depends[2] Threads[1]\nHMMBase.jl - depends[2] -\nhmmlearn NumPy[2] NumPy[2] NumPy[2]\npomegranate PyTorch[3] PyTorch[3] PyTorch[3]","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"[1]: possibly affected by JULIA_NUM_THREADS","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"[2]: possibly affected by OPENBLAS_NUM_THREADS","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"[3]: possibly affected by MKL_NUM_THREADS","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"For a fairer comparison, we set JULIA_NUM_THREADS=1, even though it robs HMMs.jl of its parallel speedup on multiple sequences.","category":"page"},{"location":"alt_performance/","page":"Performance","title":"Performance","text":"In addition, OpenBLAS threads have negative interactions with Julia threads. To overcome this obstacle, we run the Julia benchmarks (and only those) with OPENBLAS_NUM_THREADS=1.","category":"page"},{"location":"tuto_builtin/#Tutorial-built-in-HMM","page":"Built-in HMM","title":"Tutorial - built-in HMM","text":"","category":"section"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"using HiddenMarkovModels\nusing Distributions","category":"page"},{"location":"tuto_builtin/#Construction","page":"Built-in HMM","title":"Construction","text":"","category":"section"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Constructing a model:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"function random_gaussian_hmm(N)\n    p = ones(N) / N  # initial distribution\n    A = rand_trans_mat(N)  # transition matrix\n    dists = [Normal(randn(), 1.0) for n in 1:N]  # observation distributions\n    return HMM(p, A, dists)\nend;","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Checking its contents:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"hmm = random_gaussian_hmm(3)\ntransition_matrix(hmm)\n[obs_distribution(hmm, i) for i in 1:length(hmm)]","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Simulating a sequence:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"state_seq, obs_seq = rand(hmm, 1000);\nfirst(state_seq, 10)'\nfirst(obs_seq, 10)'","category":"page"},{"location":"tuto_builtin/#Inference","page":"Built-in HMM","title":"Inference","text":"","category":"section"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Computing the loglikelihood of an observation sequence:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"logdensityof(hmm, obs_seq)","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Inferring the most likely state sequence:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"most_likely_state_seq = viterbi(hmm, obs_seq);\nfirst(most_likely_state_seq, 10)'","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"Learning the parameters based on an observation sequence:","category":"page"},{"location":"tuto_builtin/","page":"Built-in HMM","title":"Built-in HMM","text":"hmm_init = random_gaussian_hmm(3)\nhmm_est, logL_evolution = baum_welch(hmm_init, obs_seq);\nfirst(logL_evolution), last(logL_evolution)\ntransition_matrix(hmm_est)\n[obs_distribution(hmm_est, i) for i in 1:length(hmm)]","category":"page"},{"location":"roadmap/#Roadmap","page":"Roadmap","title":"Roadmap","text":"","category":"section"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"Here are some of the things that I would like to work on soon-ish:","category":"page"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"numerical stability in large-dimensional settings with sparse transitions\nSIMD optimization with LoopVectorization.jl or Tullio.jl\nspectral estimation methods\ninput-output HMMs in my other package ControlledMarkovModels.jl","category":"page"},{"location":"roadmap/","page":"Roadmap","title":"Roadmap","text":"Contributors are welcome!","category":"page"},{"location":"alt_features/#Alternatives-features","page":"Features","title":"Alternatives - features","text":"","category":"section"},{"location":"alt_features/","page":"Features","title":"Features","text":"We compare features among the following Julia packages:","category":"page"},{"location":"alt_features/","page":"Features","title":"Features","text":"HiddenMarkovModels.jl (abbreviated to HMMs.jl)\nHMMBase.jl\nHMMGradients.jl\nMarkovModels.jl (coming soon)","category":"page"},{"location":"alt_features/","page":"Features","title":"Features","text":"There are also more generic packages for probabilistic programming, which are able to perform MCMC or variational inference (eg. Turing.jl) but we leave those aside.","category":"page"},{"location":"alt_features/","page":"Features","title":"Features","text":" HMMs.jl HMMBase.jl HMMGradients.jl\nAlgorithms Sim, FB, Vit, BW Sim, FB, Vit, BW FB\nObservation types anything Number / Vector anything\nObservation distributions DensityInterface.jl Distributions.jl manual\nNumber types anything Float64 AbstractFloat\nPriors / structures possible no possible\nAutomatic differentiation yes no yes\nMultiple sequences yes no yes\nLinear algebra yes yes no\nGPU support ? ? ?","category":"page"},{"location":"alt_features/","page":"Features","title":"Features","text":"Sim = Simulation, FB = Forward-Backward, Vit = Viterbi, BW = Baum-Welch","category":"page"},{"location":"background/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"background/#What-are-HMMs?","page":"Background","title":"What are HMMs?","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Hidden Markov Models (HMMs for short) are a statistical modeling framework that is ubiquitous in signal processing, bioinformatics and plenty of other fields. They capture the distribution of an observation sequence (Y_t) by assuming the existence of a latent state sequence (X_t) such that:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"the sequence (X_t) follows a (discrete time, discrete space) Markov chain\nfor each t, the distribution of Y_t is entirely determined by the value of X_t","category":"page"},{"location":"background/#What-can-we-do-with-them?","page":"Background","title":"What can we do with them?","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Imagine we are given an observation sequence (Y_t) and a parametric family of HMMs mathbbP_theta  theta in Theta. We can list several fundamental problems, each of which has a solution that relies on dynamic programming:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Problem Goal Algorithm\nEvaluation Likelihood of the observation sequence mathbbP_theta(Y_1T) Forward\nInference State marginals mathbbP_theta(X_t vert Y_1T) Forward-backward\nDecoding Most likely state sequence undersetX_1TmathrmargmaxmathbbP_theta(X_1T vert Y_1T) Viterbi\nLearning Best parameter undersetthetamathrmargmaxmathbbP_theta(Y_1T) Baum-Welch","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Our whole package is based on the tutorial by (Rabiner, 1989), you can refer to it for more details.","category":"page"},{"location":"background/#Bibliography","page":"Background","title":"Bibliography","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"","category":"page"},{"location":"tuto_custom/#Tutorial-custom-HMM","page":"Custom HMM","title":"Tutorial - custom HMM","text":"","category":"section"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"using HiddenMarkovModels\nusing Distributions","category":"page"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"The built-in HMM is perfect when the initial state distribution, transition matrix and emission distributions are separate objects, which means their re-estimation can be done separately. But in some cases these parameters might be correlated. For instance, you may want an HMM whose initial state distribution always corresponds to the equilibrium distribution associated with the transition matrix.","category":"page"},{"location":"tuto_custom/#Interface","page":"Custom HMM","title":"Interface","text":"","category":"section"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"In such cases, it is necessary to implement a new subtype of AbstractHMM with all its required methods. To ascertain that a type indeed satisfies the interface, you can use RequiredInterfaces.jl as follows:","category":"page"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"using RequiredInterfaces: check_interface_implemented\ncheck_interface_implemented(AbstractHMM, HMM)","category":"page"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"And of course, if your implementation is insufficient, the test will fail:","category":"page"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"struct EmptyHMM end\ncheck_interface_implemented(AbstractHMM, EmptyHMM)","category":"page"},{"location":"tuto_custom/","page":"Custom HMM","title":"Custom HMM","text":"Note that this test does not check the fit! method. Since it is only used in the Baum-Welch algorithm, it is an optional part of the AbstractHMM interface.","category":"page"},{"location":"tuto_custom/#Example-(coming-soon)","page":"Custom HMM","title":"Example (coming soon)","text":"","category":"section"},{"location":"formulas/#Formulas","page":"Formulas","title":"Formulas","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Suppose we are given observations Y_1  Y_T, with hidden states X_1  X_T. Following (Rabiner, 1989), we use the following notations:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"let pi in mathbbR^N be the initial state distribution pi_i = mathbbP(X_1 = i)\nlet A in mathbbR^N times N be the transition matrix a_ij = mathbbP(X_t+1=j  X_t = i)\nlet B in mathbbR^N times T be the matrix of statewise observation likelihoods b_it = mathbbP(Y_t  X_t = i)","category":"page"},{"location":"formulas/#Vanilla-forward-backward","page":"Formulas","title":"Vanilla forward-backward","text":"","category":"section"},{"location":"formulas/#Recursion","page":"Formulas","title":"Recursion","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The forward and backward variables are defined by","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_it  = mathbbP(Y_1t X_t=i) \nbeta_it  = mathbbP(Y_t+1T  X_t=i)\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"They are initialized with","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_i1  = pi_i b_i1 \nbeta_iT  = 1\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"and satisfy the dynamic programming equations","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_jt+1  = left(sum_i=1^N alpha_it a_ijright) b_jt+1 \nbeta_it  = sum_j=1^N a_ij b_jt+1 beta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Likelihood","page":"Formulas","title":"Likelihood","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The likelihood of the whole sequence of observations is given by","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"mathcalL = mathbbP(Y_1T) = sum_i=1^N alpha_iT","category":"page"},{"location":"formulas/#Marginals","page":"Formulas","title":"Marginals","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"We notice that","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nalpha_it beta_it  = mathbbP(Y_1T X_t=i) \nalpha_it a_ij b_jt+1 beta_jt+1  = mathbbP(Y_1T X_t=i X_t+1=j)\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Thus we deduce the one-state and two-state marginals","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\ngamma_it  = mathbbP(X_t=i  Y_1T) = frac1mathcalL alpha_it beta_it \nxi_ijt  = mathbbP(X_t=i X_t+1=j  Y_1T) = frac1mathcalL alpha_it a_ij b_jt+1 beta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Derivatives","page":"Formulas","title":"Derivatives","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"According to (Qin et al., 2000), derivatives of the likelihood can be obtained as follows:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial pi_i = beta_i1 b_i1 \nfracpartial mathcalLpartial a_ij = sum_t=1^T-1 alpha_it b_jt+1 beta_jt+1 \nfracpartial mathcalLpartial b_j1 = pi_j beta_j1 \nfracpartial mathcalLpartial b_jt = left(sum_i=1^N alpha_it-1 a_ijright) beta_jt \nendalign*","category":"page"},{"location":"formulas/#Scaled-forward-backward","page":"Formulas","title":"Scaled forward-backward","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"In this package, we use a slightly different version of the algorithm, including both the traditional scaling of (Rabiner, 1989) and a normalization of B using m_t = max_i b_it.","category":"page"},{"location":"formulas/#Recursion-2","page":"Formulas","title":"Recursion","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"The variables are initialized with","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nhatalpha_i1  = pi_i fracb_i1m_1  c_1  = frac1sum_i hatalpha_i1  baralpha_i1  = c_1 hatalpha_i1 \nhatbeta_iT  = 1   barbeta_1T = c_T hatbeta_1T\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"and satisfy the dynamic programming equations","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nhatalpha_jt+1  = left(sum_i=1^N baralpha_it a_ijright) fracb_jt+1m_t+1  c_t+1  = frac1sum_j hatalpha_jt+1  baralpha_jt+1 = c_t+1 hatalpha_jt+1 \nhatbeta_it  = sum_j=1^N a_ij fracb_jt+1m_t+1 barbeta_jt+1   barbeta_jt = c_t hatbeta_jt\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"In terms of the original variables, we find","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nbaralpha_it = alpha_it left(prod_s=1^t fracc_sm_sright) \nbarbeta_it = beta_it left(c_t prod_s=t+1^T fracc_sm_sright)\nendalign*","category":"page"},{"location":"formulas/#Likelihood-2","page":"Formulas","title":"Likelihood","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Since we normalized baralpha at each time step,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"1 = sum_i=1^N baralpha_iT = left(sum_i=1^N alpha_iTright) left(prod_s=1^T fracc_sm_sright) ","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"which means","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"mathcalL = sum_i=1^N alpha_iT = prod_s=1^T fracm_sc_s","category":"page"},{"location":"formulas/#Marginals-2","page":"Formulas","title":"Marginals","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"We can now express the marginals using scaled variables:","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\ngamma_it  = frac1mathcalL alpha_it beta_it = frac1mathcalL left(baralpha_it prod_s=1^t fracm_sc_sright) left(barbeta_it frac1c_t prod_s=t+1^T fracm_sc_sright) \n= frac1mathcalL fracbaralpha_it barbeta_itc_t left(prod_s=1^T fracm_sc_sright) = fracbaralpha_it barbeta_itc_t\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nxi_ijt  = frac1mathcalL alpha_it a_ij b_jt+1 beta_jt+1 \n= frac1mathcalL  left(baralpha_it prod_s=1^t fracm_sc_sright) a_ij b_jt+1 left(barbeta_jt+1 frac1c_t+1 prod_s=t+2^T fracm_sc_sright) \n= frac1mathcalL  baralpha_it a_ij fracb_jt+1m_t+1 barbeta_jt+1 left(prod_s=1^T fracm_sc_sright) \n= baralpha_it a_ij fracb_jt+1m_t+1 barbeta_jt+1\nendalign*","category":"page"},{"location":"formulas/#Derivatives-2","page":"Formulas","title":"Derivatives","text":"","category":"section"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"And we also need to adapt the derivatives. For the initial distribution,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial pi_i = beta_i1 b_i1 = left(barbeta_i1 frac1c_1 prod_s=2^T fracm_sc_s right) b_i1 \n= left(prod_s=1^T fracm_sc_sright) barbeta_i1 fracb_i1m_1  = mathcalL barbeta_i1 fracb_i1m_1 \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"For the transition matrix,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial a_ij = sum_t=1^T-1 alpha_it b_jt+1 beta_jt+1 \n= sum_t=1^T-1 left(baralpha_it prod_s=1^t fracm_sc_s right) b_jt+1 left(barbeta_jt+1 frac1c_t+1 prod_s=t+2^T fracm_sc_s right) \n= sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 left(prod_s=1^T fracm_sc_s right) \n= mathcalL sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"And for the statewise observation likelihoods,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial b_j1 = pi_j beta_j1 = pi_j barbeta_j1 frac1c_1 prod_s=2^T fracm_sc_s = mathcalL pi_j barbeta_j1 frac1m_1\nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial mathcalLpartial b_jt = left(sum_i=1^N alpha_it-1 a_ijright) beta_jt \n= sum_i=1^N left(baralpha_it-1 prod_s=1^t-1 fracm_sc_sright) a_ij left(barbeta_jt frac1c_t prod_s=t+1^T fracm_sc_s right) \n= sum_i=1^N baralpha_it-1 a_ij barbeta_jt frac1m_t left(prod_s=1^T fracm_sc_sright) \n= mathcalL sum_i=1^N baralpha_it-1 a_ij barbeta_jt frac1m_t \nendalign*","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"Finally, we note that","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"fracpartial log mathcalLpartial log b_jt = fracpartial log mathcalLpartial b_jt b_jt","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"To sum up,","category":"page"},{"location":"formulas/","page":"Formulas","title":"Formulas","text":"beginalign*\nfracpartial log mathcalLpartial pi_i = fracb_i1m_1 barbeta_i1 \nfracpartial log mathcalLpartial a_ij = sum_t=1^T-1 baralpha_it fracb_jt+1m_t+1 barbeta_jt+1 \nfracpartial log mathcalLpartial log b_j1 = pi_j fracb_j1m_1 barbeta_j1 = fracbaralpha_j1 barbeta_j1c_1 = gamma_j1 \nfracpartial log mathcalLpartial log b_jt = sum_i=1^N baralpha_it-1 a_ij fracb_jtm_t barbeta_jt = fracbaralpha_jt barbeta_jtc_t = gamma_jt\nendalign*","category":"page"},{"location":"","page":"Home","title":"Home","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/README.md\"","category":"page"},{"location":"#HiddenMarkovModels.jl","page":"Home","title":"HiddenMarkovModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: DOI) (Image: Aqua QA) (Image: JET)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Julia package for HMM modeling, simulation, inference and learning.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package can be installed using Julia's package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add HiddenMarkovModels","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, you can create your first HMM as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Distributions, HiddenMarkovModels\ninit = [0.2, 0.8]\ntrans = [0.1 0.9; 0.7 0.3]\ndists = [Normal(-1), Normal(1)]\nhmm = HMM(init, trans, dists)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Take a look at the documentation to know what to do next!","category":"page"},{"location":"#Main-features","page":"Home","title":"Main features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is generic. Observations can be arbitrary Julia objects, not just scalars or arrays. Their distributions only need to implement rand(rng, dist) and logdensityof(dist, x) from DensityInterface.jl. Number types are not restricted to floating point, and automatic differentiation is supported in forward mode (ForwardDiff.jl) and reverse mode (ChainRules.jl).","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is fast. All the inference functions have allocation-free versions, which leverage efficient linear algebra subroutines. Multithreading is used to parallelize computations across sequences, and compatibility with various array types (SparseArrays.jl and StaticArrays.jl) is ensured. We include extensive benchmarks against Julia and Python competitors thanks to BenchmarkTools.jl and PythonCall.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is reliable. It gives the same results as the previous reference package HMMBase.jl up to numerical accuracy. The test suite incorporates quality checks with Aqua.jl, as well as linting and type stability checks with JET.jl. A detailed documentation will help you find the functions you need.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you spot a bug or want to ask about a new feature, please open an issue on the GitHub repository. Once the issue receives positive feedback, feel free to try and fix it with a pull request that follows the BlueStyle guidelines.","category":"page"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A big thank you to Maxime Mouchet and Jacob Schreiber, the respective lead devs of HMMBase.jl and pomegranate, for their help and advice. Logo by Clément Mantoux based on a portrait of Andrey Markov.","category":"page"}]
}
